\documentclass[pdftex,12pt,letter]{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{cite}
\usepackage{url}
\usepackage[pdftex,pdfpagelabels,bookmarks,hyperindex,hyperfigures]{hyperref}


\title{Modern architectures of the Conditions Database Systems and their potential applications in DUNE}
\date{\today}
\author{P.\,Laycock, M.\,Potekhin}


\begin{document}
\maketitle

\begin{abstract}
\noindent  In the past few years the HEP community has developed fresh understanding of
the use cases and challenges of the Conditions Database systems based on the experience of
the LHC and other experiments. New and converging designs have been created and implemented
in experiments such as CMS, Belle II and others. We consider the features of these
new architectures and potential advantages they can bring to DUNE.

%% \cite{docdb1086}, DocDB\ and
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Overview}
According to  the HSF document \textit{``A Roadmap for HEP Software and Computing R\&D for the 2020s''} \cite{hsf_roadmap},
\begin{quote}
Conditions data is defined as the non-event data required by data-processing software to correctly simulate, digitise or reconstruct the raw detector event data. The
non-event data discussed here consists mainly of detector calibration and alignment
information, with some additional data describing the detector configuration, the
machine parameters, as well as information from the detector control system.
\end{quote}

\noindent It is important to note that the conditions data comprises a considerable variety of information,
which may also come in different formats and in different volumes depending on the use case.


\subsection{Motivation}
\underline{DUNE}

\subsection{Data Scenarios and Data Handling}
\label{sec:rawdata}

\subsection{Data Streams}
\label{sec:streams}

For reasons that are outside of the scope of this document  the experimental raw data
will come as three distinct streams at the time they are captured:
\begin{itemize}
\item \textbf{LArTPC} The TPC  stream which is dominant in terms of rate and volume
\item \textbf{BI} Beam Instrumentation data from Cherenkov, TOF and other systems
\item \textbf{CRT} Cosmic Ray Tagger data
\end{itemize}

\noindent All three streams will follow a similar path in that they will be transmitted from their respective
online buffers.


%% \begin{figure}[tbh]
%%   \centering
%%   \includegraphics[width=1.1\textwidth]{figures/prompt_queues_1.pdf}
%%   \caption{Categories of prompt processing jobs grouped in queues. In this example, the depths of queues are different for different job types.}
%%   \label{fig:queues1}
%% \end{figure}


%%\newpage
%%\appendix
%%\section{Glossary}
%%\label{sec:glossary}
%%\begin{description}
%%\item [foo] description
%%\end{description}


\clearpage
\begin{thebibliography}{1}
\bibitem{hsf_roadmap}
{\textit{A Roadmap for HEP Software and Computing R\&D for the 2020s}arXiv:1712.06982} \url{https://arxiv.org/abs/1712.06982}

\bibitem{condb}
{\textit{Conditions Database at Fermilab}  \url{https://cdcvs.fnal.gov/redmine/projects/condb/wiki/Conditions_Database_at_Fermilab}}

\end{thebibliography}


\end{document}
